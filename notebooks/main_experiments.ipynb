{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0fbaad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../')) # Point to project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cadb346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules reloaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessandrobenvenuti/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/gymnasium/envs/registration.py:644: UserWarning: \u001b[33mWARN: Overriding environment CustomHopper-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/Users/alessandrobenvenuti/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/gymnasium/envs/registration.py:644: UserWarning: \u001b[33mWARN: Overriding environment CustomHopper-source-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/Users/alessandrobenvenuti/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/gymnasium/envs/registration.py:644: UserWarning: \u001b[33mWARN: Overriding environment CustomHopper-target-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import modules.trainer\n",
    "import modules.utils\n",
    "import modules.callbacks\n",
    "import modules.env\n",
    "import env.custom_hopper\n",
    "\n",
    "# Force reload of the modules you changed\n",
    "importlib.reload(modules.env)\n",
    "importlib.reload(modules.callbacks)\n",
    "importlib.reload(modules.utils)\n",
    "importlib.reload(modules.trainer)\n",
    "importlib.reload(env.custom_hopper)\n",
    "\n",
    "# Re-import the specific functions into the global namespace\n",
    "from modules.trainer import train_agent\n",
    "from modules.utils import plot_learning_curve, plot_doraemon_dynamics\n",
    "from env.custom_hopper import *\n",
    "\n",
    "print(\"Modules reloaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f475190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.trainer import train_agent\n",
    "from modules.utils import *\n",
    "from env.custom_hopper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bc1f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'env_id': 'CustomHopper-source-v0',\n",
    "    'algo': 'sac',\n",
    "    'seed': 42,\n",
    "    'timesteps': 1_000_000,\n",
    "    'vectorize': True,\n",
    "    'normalize': True, \n",
    "    'lr': 1e-3,\n",
    "    \n",
    "    # DORAEMON Settings\n",
    "    'use_doraemon': True,     # This triggers GaussianHopperWrapper + DoraemonCallback\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "937e0e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING NEW TRAINING ---\n",
      "Using cpu device\n",
      "Logging to ./tensorboard_logs/SAC_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.8     |\n",
      "|    ep_rew_mean     | 18.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 3726     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 95       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21       |\n",
      "|    ep_rew_mean     | 15.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 379      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 168      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.97    |\n",
      "|    critic_loss     | 0.385    |\n",
      "|    ent_coef        | 0.936    |\n",
      "|    ent_coef_loss   | -0.333   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 67       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.7     |\n",
      "|    ep_rew_mean     | 20       |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 256      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 272      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.74    |\n",
      "|    critic_loss     | 0.397    |\n",
      "|    ent_coef        | 0.844    |\n",
      "|    ent_coef_loss   | -0.855   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 171      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.2     |\n",
      "|    ep_rew_mean     | 30.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 199      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 436      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.67    |\n",
      "|    critic_loss     | 0.352    |\n",
      "|    ent_coef        | 0.716    |\n",
      "|    ent_coef_loss   | -1.67    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 335      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.2     |\n",
      "|    ep_rew_mean     | 30.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 178      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 585      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.66    |\n",
      "|    critic_loss     | 0.104    |\n",
      "|    ent_coef        | 0.618    |\n",
      "|    ent_coef_loss   | -2.35    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 484      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 38       |\n",
      "|    ep_rew_mean     | 47.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 174      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 911      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.81    |\n",
      "|    critic_loss     | 0.23     |\n",
      "|    ent_coef        | 0.451    |\n",
      "|    ent_coef_loss   | -3.69    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 810      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 38.7     |\n",
      "|    ep_rew_mean     | 51.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 172      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 1083     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.6    |\n",
      "|    critic_loss     | 1.42     |\n",
      "|    ent_coef        | 0.385    |\n",
      "|    ent_coef_loss   | -3.93    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 982      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 40.9     |\n",
      "|    ep_rew_mean     | 57.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 164      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 1309     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.7    |\n",
      "|    critic_loss     | 1.09     |\n",
      "|    ent_coef        | 0.315    |\n",
      "|    ent_coef_loss   | -4.44    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1208     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 47.9     |\n",
      "|    ep_rew_mean     | 78.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 165      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 1723     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.1    |\n",
      "|    critic_loss     | 0.483    |\n",
      "|    ent_coef        | 0.224    |\n",
      "|    ent_coef_loss   | -4.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1622     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 54.7     |\n",
      "|    ep_rew_mean     | 97.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 164      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 2188     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -21.8    |\n",
      "|    critic_loss     | 3.4      |\n",
      "|    ent_coef        | 0.157    |\n",
      "|    ent_coef_loss   | -4.31    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2087     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 59.8     |\n",
      "|    ep_rew_mean     | 112      |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 165      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 2632     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -27      |\n",
      "|    critic_loss     | 1.44     |\n",
      "|    ent_coef        | 0.116    |\n",
      "|    ent_coef_loss   | -4.37    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2531     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 63.2     |\n",
      "|    ep_rew_mean     | 122      |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 165      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 3032     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -31.1    |\n",
      "|    critic_loss     | 2.35     |\n",
      "|    ent_coef        | 0.0926   |\n",
      "|    ent_coef_loss   | -3.95    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2931     |\n",
      "---------------------------------\n",
      "[DORAEMON] Step 3278: Success=0.00 | Lambda=1.08 | Mean=[1. 1. 1.] | Std=[0.01051271 0.01051271 0.01051271]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 67.7     |\n",
      "|    ep_rew_mean     | 138      |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 167      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 3521     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -36.3    |\n",
      "|    critic_loss     | 1.87     |\n",
      "|    ent_coef        | 0.0742   |\n",
      "|    ent_coef_loss   | -2.69    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3420     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 71.7     |\n",
      "|    ep_rew_mean     | 152      |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 167      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 4015     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -42.6    |\n",
      "|    critic_loss     | 1.58     |\n",
      "|    ent_coef        | 0.0651   |\n",
      "|    ent_coef_loss   | -1.06    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3914     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76       |\n",
      "|    ep_rew_mean     | 167      |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 167      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 4562     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -47.6    |\n",
      "|    critic_loss     | 4.66     |\n",
      "|    ent_coef        | 0.0594   |\n",
      "|    ent_coef_loss   | 0.00665  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4461     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80.5     |\n",
      "|    ep_rew_mean     | 180      |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 167      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 5153     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -55      |\n",
      "|    critic_loss     | 1.53     |\n",
      "|    ent_coef        | 0.0561   |\n",
      "|    ent_coef_loss   | -0.0125  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5052     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 83       |\n",
      "|    ep_rew_mean     | 190      |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 167      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 5641     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -57.8    |\n",
      "|    critic_loss     | 9.73     |\n",
      "|    ent_coef        | 0.0565   |\n",
      "|    ent_coef_loss   | -0.436   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5540     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 85.1     |\n",
      "|    ep_rew_mean     | 198      |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 167      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 6126     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -64.2    |\n",
      "|    critic_loss     | 1.78     |\n",
      "|    ent_coef        | 0.0612   |\n",
      "|    ent_coef_loss   | 0.895    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6025     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 86.6     |\n",
      "|    ep_rew_mean     | 203      |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 39       |\n",
      "|    total_timesteps | 6582     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -66.9    |\n",
      "|    critic_loss     | 2.79     |\n",
      "|    ent_coef        | 0.067    |\n",
      "|    ent_coef_loss   | 1.37     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6481     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 89.3     |\n",
      "|    ep_rew_mean     | 212      |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 7141     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -74.9    |\n",
      "|    critic_loss     | 1.98     |\n",
      "|    ent_coef        | 0.0808   |\n",
      "|    ent_coef_loss   | -0.408   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7040     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 90.2     |\n",
      "|    ep_rew_mean     | 217      |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 44       |\n",
      "|    total_timesteps | 7579     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -78      |\n",
      "|    critic_loss     | 3.17     |\n",
      "|    ent_coef        | 0.0776   |\n",
      "|    ent_coef_loss   | -1.28    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7478     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 92.4     |\n",
      "|    ep_rew_mean     | 225      |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 8127     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.1    |\n",
      "|    critic_loss     | 2.84     |\n",
      "|    ent_coef        | 0.0752   |\n",
      "|    ent_coef_loss   | 0.294    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8026     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 94.6     |\n",
      "|    ep_rew_mean     | 232      |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 51       |\n",
      "|    total_timesteps | 8701     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.7    |\n",
      "|    critic_loss     | 2.69     |\n",
      "|    ent_coef        | 0.0816   |\n",
      "|    ent_coef_loss   | -0.974   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8600     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 97.2     |\n",
      "|    ep_rew_mean     | 242      |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 55       |\n",
      "|    total_timesteps | 9334     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.5    |\n",
      "|    critic_loss     | 4.23     |\n",
      "|    ent_coef        | 0.0835   |\n",
      "|    ent_coef_loss   | -0.0374  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9233     |\n",
      "---------------------------------\n",
      "[DORAEMON] Step 9987: Success=0.00 | Lambda=1.16 | Mean=[1. 1. 1.] | Std=[0.01105171 0.01105171 0.01105171]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 99.9     |\n",
      "|    ep_rew_mean     | 252      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 59       |\n",
      "|    total_timesteps | 9987     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 5.58     |\n",
      "|    ent_coef        | 0.0844   |\n",
      "|    ent_coef_loss   | 0.781    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9886     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | 265      |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 62       |\n",
      "|    total_timesteps | 10484    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 4.84     |\n",
      "|    ent_coef        | 0.0848   |\n",
      "|    ent_coef_loss   | -0.022   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 10383    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 65       |\n",
      "|    total_timesteps | 11102    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -111     |\n",
      "|    critic_loss     | 4.78     |\n",
      "|    ent_coef        | 0.0854   |\n",
      "|    ent_coef_loss   | -0.0324  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11001    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | 292      |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 68       |\n",
      "|    total_timesteps | 11513    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -114     |\n",
      "|    critic_loss     | 4.73     |\n",
      "|    ent_coef        | 0.0932   |\n",
      "|    ent_coef_loss   | -0.15    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11412    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 115      |\n",
      "|    ep_rew_mean     | 300      |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 70       |\n",
      "|    total_timesteps | 11933    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -117     |\n",
      "|    critic_loss     | 8.28     |\n",
      "|    ent_coef        | 0.0895   |\n",
      "|    ent_coef_loss   | 1.28     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11832    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 120      |\n",
      "|    ep_rew_mean     | 315      |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 74       |\n",
      "|    total_timesteps | 12558    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -119     |\n",
      "|    critic_loss     | 4.59     |\n",
      "|    ent_coef        | 0.0939   |\n",
      "|    ent_coef_loss   | 0.243    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 12457    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 121      |\n",
      "|    ep_rew_mean     | 321      |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 76       |\n",
      "|    total_timesteps | 13001    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -122     |\n",
      "|    critic_loss     | 7.49     |\n",
      "|    ent_coef        | 0.0924   |\n",
      "|    ent_coef_loss   | 0.733    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 12900    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 125      |\n",
      "|    ep_rew_mean     | 335      |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 80       |\n",
      "|    total_timesteps | 13569    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 5.14     |\n",
      "|    ent_coef        | 0.0991   |\n",
      "|    ent_coef_loss   | 0.599    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 13468    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 129      |\n",
      "|    ep_rew_mean     | 351      |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 84       |\n",
      "|    total_timesteps | 14195    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -133     |\n",
      "|    critic_loss     | 5.71     |\n",
      "|    ent_coef        | 0.097    |\n",
      "|    ent_coef_loss   | 0.232    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 14094    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 131      |\n",
      "|    ep_rew_mean     | 362      |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 88       |\n",
      "|    total_timesteps | 14855    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -136     |\n",
      "|    critic_loss     | 5.62     |\n",
      "|    ent_coef        | 0.1      |\n",
      "|    ent_coef_loss   | -0.296   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 14754    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 132      |\n",
      "|    ep_rew_mean     | 369      |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 91       |\n",
      "|    total_timesteps | 15422    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -143     |\n",
      "|    critic_loss     | 7.56     |\n",
      "|    ent_coef        | 0.102    |\n",
      "|    ent_coef_loss   | 0.699    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 15321    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 135      |\n",
      "|    ep_rew_mean     | 380      |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 95       |\n",
      "|    total_timesteps | 16130    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -148     |\n",
      "|    critic_loss     | 5.17     |\n",
      "|    ent_coef        | 0.0966   |\n",
      "|    ent_coef_loss   | 0.718    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 16029    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 138      |\n",
      "|    ep_rew_mean     | 394      |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 99       |\n",
      "|    total_timesteps | 16872    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -148     |\n",
      "|    critic_loss     | 5.69     |\n",
      "|    ent_coef        | 0.106    |\n",
      "|    ent_coef_loss   | -1       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 16771    |\n",
      "---------------------------------\n",
      "[DORAEMON] Step 17259: Success=0.00 | Lambda=1.24 | Mean=[1. 1. 1.] | Std=[0.01161835 0.01161835 0.01161835]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 141      |\n",
      "|    ep_rew_mean     | 408      |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 104      |\n",
      "|    total_timesteps | 17668    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -153     |\n",
      "|    critic_loss     | 6.46     |\n",
      "|    ent_coef        | 0.11     |\n",
      "|    ent_coef_loss   | 0.402    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 17567    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 144      |\n",
      "|    ep_rew_mean     | 416      |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 108      |\n",
      "|    total_timesteps | 18390    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -152     |\n",
      "|    critic_loss     | 6.55     |\n",
      "|    ent_coef        | 0.113    |\n",
      "|    ent_coef_loss   | 0.187    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 18289    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 146      |\n",
      "|    ep_rew_mean     | 428      |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 19195    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -166     |\n",
      "|    critic_loss     | 5.93     |\n",
      "|    ent_coef        | 0.107    |\n",
      "|    ent_coef_loss   | 0.844    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 19094    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 148      |\n",
      "|    ep_rew_mean     | 440      |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 118      |\n",
      "|    total_timesteps | 19995    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -162     |\n",
      "|    critic_loss     | 7.34     |\n",
      "|    ent_coef        | 0.1      |\n",
      "|    ent_coef_loss   | -0.273   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 19894    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 152      |\n",
      "|    ep_rew_mean     | 455      |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 123      |\n",
      "|    total_timesteps | 20887    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -168     |\n",
      "|    critic_loss     | 5.76     |\n",
      "|    ent_coef        | 0.102    |\n",
      "|    ent_coef_loss   | -0.00559 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 20786    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 157      |\n",
      "|    ep_rew_mean     | 472      |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 129      |\n",
      "|    total_timesteps | 21807    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -174     |\n",
      "|    critic_loss     | 5.37     |\n",
      "|    ent_coef        | 0.104    |\n",
      "|    ent_coef_loss   | -0.84    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 21706    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 160      |\n",
      "|    ep_rew_mean     | 483      |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 133      |\n",
      "|    total_timesteps | 22536    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -166     |\n",
      "|    critic_loss     | 6.75     |\n",
      "|    ent_coef        | 0.104    |\n",
      "|    ent_coef_loss   | 0.264    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 22435    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 164      |\n",
      "|    ep_rew_mean     | 500      |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 139      |\n",
      "|    total_timesteps | 23541    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -176     |\n",
      "|    critic_loss     | 12.5     |\n",
      "|    ent_coef        | 0.106    |\n",
      "|    ent_coef_loss   | 0.144    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 23440    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 168      |\n",
      "|    ep_rew_mean     | 517      |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 144      |\n",
      "|    total_timesteps | 24408    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 6.23     |\n",
      "|    ent_coef        | 0.0985   |\n",
      "|    ent_coef_loss   | -0.317   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 24307    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 171      |\n",
      "|    ep_rew_mean     | 529      |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 149      |\n",
      "|    total_timesteps | 25269    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -188     |\n",
      "|    critic_loss     | 5.18     |\n",
      "|    ent_coef        | 0.103    |\n",
      "|    ent_coef_loss   | 0.071    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 25168    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 176      |\n",
      "|    ep_rew_mean     | 545      |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 155      |\n",
      "|    total_timesteps | 26264    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 6.46     |\n",
      "|    ent_coef        | 0.101    |\n",
      "|    ent_coef_loss   | 0.606    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 26163    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 179      |\n",
      "|    ep_rew_mean     | 560      |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 161      |\n",
      "|    total_timesteps | 27256    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 7.13     |\n",
      "|    ent_coef        | 0.0972   |\n",
      "|    ent_coef_loss   | 0.441    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 27155    |\n",
      "---------------------------------\n",
      "[DORAEMON] Step 28248: Success=0.00 | Lambda=1.32 | Mean=[1. 1. 1.] | Std=[0.01221404 0.01221404 0.01221404]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 183      |\n",
      "|    ep_rew_mean     | 574      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 167      |\n",
      "|    total_timesteps | 28248    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -198     |\n",
      "|    critic_loss     | 6.39     |\n",
      "|    ent_coef        | 0.0944   |\n",
      "|    ent_coef_loss   | 0.122    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 28147    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 187      |\n",
      "|    ep_rew_mean     | 595      |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 173      |\n",
      "|    total_timesteps | 29233    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -194     |\n",
      "|    critic_loss     | 7.48     |\n",
      "|    ent_coef        | 0.0955   |\n",
      "|    ent_coef_loss   | 0.135    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 29132    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 192      |\n",
      "|    ep_rew_mean     | 614      |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 179      |\n",
      "|    total_timesteps | 30341    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -201     |\n",
      "|    critic_loss     | 8.34     |\n",
      "|    ent_coef        | 0.0941   |\n",
      "|    ent_coef_loss   | 0.0403   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 30240    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 641      |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 186      |\n",
      "|    total_timesteps | 31491    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -205     |\n",
      "|    critic_loss     | 6.07     |\n",
      "|    ent_coef        | 0.0981   |\n",
      "|    ent_coef_loss   | -0.574   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 31390    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 204      |\n",
      "|    ep_rew_mean     | 661      |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 191      |\n",
      "|    total_timesteps | 32381    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -200     |\n",
      "|    critic_loss     | 6.95     |\n",
      "|    ent_coef        | 0.0953   |\n",
      "|    ent_coef_loss   | 0.719    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 32280    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 206      |\n",
      "|    ep_rew_mean     | 667      |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 195      |\n",
      "|    total_timesteps | 33112    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 9.96     |\n",
      "|    ent_coef        | 0.0959   |\n",
      "|    ent_coef_loss   | 0.929    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 33011    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 210      |\n",
      "|    ep_rew_mean     | 685      |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 201      |\n",
      "|    total_timesteps | 34041    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -203     |\n",
      "|    critic_loss     | 8.7      |\n",
      "|    ent_coef        | 0.103    |\n",
      "|    ent_coef_loss   | -0.26    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 33940    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 216      |\n",
      "|    ep_rew_mean     | 708      |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 208      |\n",
      "|    total_timesteps | 35200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -206     |\n",
      "|    critic_loss     | 6.7      |\n",
      "|    ent_coef        | 0.0926   |\n",
      "|    ent_coef_loss   | 0.468    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 35099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 222      |\n",
      "|    ep_rew_mean     | 729      |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 215      |\n",
      "|    total_timesteps | 36381    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -209     |\n",
      "|    critic_loss     | 6.75     |\n",
      "|    ent_coef        | 0.09     |\n",
      "|    ent_coef_loss   | 0.0948   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 36280    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 225      |\n",
      "|    ep_rew_mean     | 743      |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 220      |\n",
      "|    total_timesteps | 37361    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -208     |\n",
      "|    critic_loss     | 8.38     |\n",
      "|    ent_coef        | 0.0954   |\n",
      "|    ent_coef_loss   | -0.15    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 37260    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 228      |\n",
      "|    ep_rew_mean     | 753      |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 225      |\n",
      "|    total_timesteps | 38221    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -210     |\n",
      "|    critic_loss     | 7.49     |\n",
      "|    ent_coef        | 0.0961   |\n",
      "|    ent_coef_loss   | -0.392   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 38120    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 231      |\n",
      "|    ep_rew_mean     | 765      |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 231      |\n",
      "|    total_timesteps | 39248    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -217     |\n",
      "|    critic_loss     | 7.55     |\n",
      "|    ent_coef        | 0.0936   |\n",
      "|    ent_coef_loss   | -0.348   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 39147    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 236      |\n",
      "|    ep_rew_mean     | 783      |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 238      |\n",
      "|    total_timesteps | 40450    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -218     |\n",
      "|    critic_loss     | 8.13     |\n",
      "|    ent_coef        | 0.0909   |\n",
      "|    ent_coef_loss   | 0.113    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 40349    |\n",
      "---------------------------------\n",
      "[DORAEMON] Step 41210: Success=0.04 | Lambda=1.40 | Mean=[0.95 0.95 0.95] | Std=[0.01284027 0.01284027 0.01284027]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 242      |\n",
      "|    ep_rew_mean     | 805      |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 247      |\n",
      "|    total_timesteps | 41901    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -213     |\n",
      "|    critic_loss     | 8.51     |\n",
      "|    ent_coef        | 0.0913   |\n",
      "|    ent_coef_loss   | -0.132   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 41800    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 253      |\n",
      "|    ep_rew_mean     | 839      |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 257      |\n",
      "|    total_timesteps | 43714    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -221     |\n",
      "|    critic_loss     | 6.76     |\n",
      "|    ent_coef        | 0.0893   |\n",
      "|    ent_coef_loss   | -0.895   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 43613    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 261      |\n",
      "|    ep_rew_mean     | 865      |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 267      |\n",
      "|    total_timesteps | 45344    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -222     |\n",
      "|    critic_loss     | 12.7     |\n",
      "|    ent_coef        | 0.0813   |\n",
      "|    ent_coef_loss   | 0.0587   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 45243    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 268      |\n",
      "|    ep_rew_mean     | 885      |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 276      |\n",
      "|    total_timesteps | 46806    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -218     |\n",
      "|    critic_loss     | 10.9     |\n",
      "|    ent_coef        | 0.0823   |\n",
      "|    ent_coef_loss   | -0.00625 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 46705    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 274      |\n",
      "|    ep_rew_mean     | 903      |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 284      |\n",
      "|    total_timesteps | 48254    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -219     |\n",
      "|    critic_loss     | 6.15     |\n",
      "|    ent_coef        | 0.0866   |\n",
      "|    ent_coef_loss   | 0.527    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 48153    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 272      |\n",
      "|    ep_rew_mean     | 891      |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 289      |\n",
      "|    total_timesteps | 49048    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -229     |\n",
      "|    critic_loss     | 7.27     |\n",
      "|    ent_coef        | 0.0856   |\n",
      "|    ent_coef_loss   | -0.0427  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 48947    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 281      |\n",
      "|    ep_rew_mean     | 921      |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 298      |\n",
      "|    total_timesteps | 50661    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -218     |\n",
      "|    critic_loss     | 6.13     |\n",
      "|    ent_coef        | 0.0812   |\n",
      "|    ent_coef_loss   | 0.0454   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 50560    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 286      |\n",
      "|    ep_rew_mean     | 939      |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 306      |\n",
      "|    total_timesteps | 52091    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -227     |\n",
      "|    critic_loss     | 7.15     |\n",
      "|    ent_coef        | 0.0791   |\n",
      "|    ent_coef_loss   | 1.21     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 51990    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 289      |\n",
      "|    ep_rew_mean     | 954      |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 314      |\n",
      "|    total_timesteps | 53329    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -233     |\n",
      "|    critic_loss     | 6.87     |\n",
      "|    ent_coef        | 0.0745   |\n",
      "|    ent_coef_loss   | 0.155    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 53228    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 295      |\n",
      "|    ep_rew_mean     | 975      |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 323      |\n",
      "|    total_timesteps | 54773    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -225     |\n",
      "|    critic_loss     | 10.1     |\n",
      "|    ent_coef        | 0.0756   |\n",
      "|    ent_coef_loss   | 0.854    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 54672    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 297      |\n",
      "|    ep_rew_mean     | 985      |\n",
      "| time/              |          |\n",
      "|    episodes        | 292      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 330      |\n",
      "|    total_timesteps | 55976    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -226     |\n",
      "|    critic_loss     | 8.33     |\n",
      "|    ent_coef        | 0.0745   |\n",
      "|    ent_coef_loss   | 0.397    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 55875    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 306      |\n",
      "|    ep_rew_mean     | 1.02e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 341      |\n",
      "|    total_timesteps | 57818    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -230     |\n",
      "|    critic_loss     | 5.99     |\n",
      "|    ent_coef        | 0.0705   |\n",
      "|    ent_coef_loss   | -0.102   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 57717    |\n",
      "---------------------------------\n",
      "[DORAEMON] Step 59456: Success=0.40 | Lambda=1.44 | Mean=[1.  1.  0.9] | Std=[0.0134986 0.0134986 0.0134986]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 312      |\n",
      "|    ep_rew_mean     | 1.04e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 350      |\n",
      "|    total_timesteps | 59456    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -239     |\n",
      "|    critic_loss     | 6.43     |\n",
      "|    ent_coef        | 0.0657   |\n",
      "|    ent_coef_loss   | -0.325   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 59355    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 316      |\n",
      "|    ep_rew_mean     | 1.05e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 304      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 358      |\n",
      "|    total_timesteps | 60809    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -235     |\n",
      "|    critic_loss     | 8        |\n",
      "|    ent_coef        | 0.0695   |\n",
      "|    ent_coef_loss   | 0.422    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 60708    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 324      |\n",
      "|    ep_rew_mean     | 1.08e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 308      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 369      |\n",
      "|    total_timesteps | 62705    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -244     |\n",
      "|    critic_loss     | 10.6     |\n",
      "|    ent_coef        | 0.0677   |\n",
      "|    ent_coef_loss   | -0.293   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 62604    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 329      |\n",
      "|    ep_rew_mean     | 1.1e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 312      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 378      |\n",
      "|    total_timesteps | 64399    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -241     |\n",
      "|    critic_loss     | 4.8      |\n",
      "|    ent_coef        | 0.0661   |\n",
      "|    ent_coef_loss   | -0.0882  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 64298    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 336      |\n",
      "|    ep_rew_mean     | 1.13e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 316      |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 388      |\n",
      "|    total_timesteps | 66002    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -247     |\n",
      "|    critic_loss     | 4.29     |\n",
      "|    ent_coef        | 0.065    |\n",
      "|    ent_coef_loss   | 0.523    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 65901    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 344      |\n",
      "|    ep_rew_mean     | 1.16e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 320      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 397      |\n",
      "|    total_timesteps | 67526    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -246     |\n",
      "|    critic_loss     | 4.34     |\n",
      "|    ent_coef        | 0.0661   |\n",
      "|    ent_coef_loss   | -0.996   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 67425    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 351      |\n",
      "|    ep_rew_mean     | 1.18e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 324      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 406      |\n",
      "|    total_timesteps | 69123    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -230     |\n",
      "|    critic_loss     | 8.66     |\n",
      "|    ent_coef        | 0.0635   |\n",
      "|    ent_coef_loss   | 0.195    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 69022    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 353      |\n",
      "|    ep_rew_mean     | 1.19e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 328      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 414      |\n",
      "|    total_timesteps | 70547    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -244     |\n",
      "|    critic_loss     | 5.11     |\n",
      "|    ent_coef        | 0.0611   |\n",
      "|    ent_coef_loss   | -0.707   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 70446    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 355      |\n",
      "|    ep_rew_mean     | 1.2e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 332      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 422      |\n",
      "|    total_timesteps | 71853    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -249     |\n",
      "|    critic_loss     | 25.6     |\n",
      "|    ent_coef        | 0.0609   |\n",
      "|    ent_coef_loss   | -1.02    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 71752    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 365      |\n",
      "|    ep_rew_mean     | 1.23e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 336      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 433      |\n",
      "|    total_timesteps | 73838    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -244     |\n",
      "|    critic_loss     | 6.03     |\n",
      "|    ent_coef        | 0.0606   |\n",
      "|    ent_coef_loss   | 0.0418   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 73737    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 368      |\n",
      "|    ep_rew_mean     | 1.25e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 340      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 440      |\n",
      "|    total_timesteps | 75003    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -251     |\n",
      "|    critic_loss     | 4.72     |\n",
      "|    ent_coef        | 0.0629   |\n",
      "|    ent_coef_loss   | 0.375    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 74902    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 372      |\n",
      "|    ep_rew_mean     | 1.26e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 344      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 448      |\n",
      "|    total_timesteps | 76400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -246     |\n",
      "|    critic_loss     | 5.44     |\n",
      "|    ent_coef        | 0.0595   |\n",
      "|    ent_coef_loss   | 0.243    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 76299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 374      |\n",
      "|    ep_rew_mean     | 1.27e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 348      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 457      |\n",
      "|    total_timesteps | 77818    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -246     |\n",
      "|    critic_loss     | 5.13     |\n",
      "|    ent_coef        | 0.0597   |\n",
      "|    ent_coef_loss   | -0.337   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 77717    |\n",
      "---------------------------------\n",
      "[DORAEMON] Step 78424: Success=0.46 | Lambda=1.47 | Mean=[0.95       1.05       0.84999996] | Std=[0.01419069 0.01419069 0.01419069]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 373      |\n",
      "|    ep_rew_mean     | 1.28e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 352      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 465      |\n",
      "|    total_timesteps | 79207    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -246     |\n",
      "|    critic_loss     | 5.66     |\n",
      "|    ent_coef        | 0.0609   |\n",
      "|    ent_coef_loss   | -0.557   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 79106    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 375      |\n",
      "|    ep_rew_mean     | 1.28e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 356      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 476      |\n",
      "|    total_timesteps | 81207    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -252     |\n",
      "|    critic_loss     | 5.59     |\n",
      "|    ent_coef        | 0.0589   |\n",
      "|    ent_coef_loss   | 0.319    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 81106    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 377      |\n",
      "|    ep_rew_mean     | 1.29e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 360      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 487      |\n",
      "|    total_timesteps | 83020    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -257     |\n",
      "|    critic_loss     | 6.56     |\n",
      "|    ent_coef        | 0.0569   |\n",
      "|    ent_coef_loss   | -0.886   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 82919    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 377      |\n",
      "|    ep_rew_mean     | 1.3e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 364      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 496      |\n",
      "|    total_timesteps | 84538    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -246     |\n",
      "|    critic_loss     | 8.03     |\n",
      "|    ent_coef        | 0.0557   |\n",
      "|    ent_coef_loss   | 0.728    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 84437    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 378      |\n",
      "|    ep_rew_mean     | 1.31e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 368      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 504      |\n",
      "|    total_timesteps | 86066    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -250     |\n",
      "|    critic_loss     | 6.89     |\n",
      "|    ent_coef        | 0.0539   |\n",
      "|    ent_coef_loss   | 0.828    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 85965    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 386      |\n",
      "|    ep_rew_mean     | 1.35e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 372      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 514      |\n",
      "|    total_timesteps | 87664    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -246     |\n",
      "|    critic_loss     | 6.38     |\n",
      "|    ent_coef        | 0.0532   |\n",
      "|    ent_coef_loss   | -0.74    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 87563    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 388      |\n",
      "|    ep_rew_mean     | 1.35e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 376      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 524      |\n",
      "|    total_timesteps | 89459    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -245     |\n",
      "|    critic_loss     | 18.1     |\n",
      "|    ent_coef        | 0.0551   |\n",
      "|    ent_coef_loss   | 1.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 89358    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 392      |\n",
      "|    ep_rew_mean     | 1.37e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 380      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 535      |\n",
      "|    total_timesteps | 91326    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -256     |\n",
      "|    critic_loss     | 3.06     |\n",
      "|    ent_coef        | 0.0553   |\n",
      "|    ent_coef_loss   | 0.11     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 91225    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 396      |\n",
      "|    ep_rew_mean     | 1.39e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 384      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 545      |\n",
      "|    total_timesteps | 92917    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -259     |\n",
      "|    critic_loss     | 5.63     |\n",
      "|    ent_coef        | 0.0519   |\n",
      "|    ent_coef_loss   | -0.224   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 92816    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | 1.4e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 388      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 555      |\n",
      "|    total_timesteps | 94765    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -261     |\n",
      "|    critic_loss     | 3.61     |\n",
      "|    ent_coef        | 0.0503   |\n",
      "|    ent_coef_loss   | -0.253   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 94664    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 406      |\n",
      "|    ep_rew_mean     | 1.42e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 392      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 566      |\n",
      "|    total_timesteps | 96541    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -253     |\n",
      "|    critic_loss     | 5.16     |\n",
      "|    ent_coef        | 0.0514   |\n",
      "|    ent_coef_loss   | 0.0611   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 96440    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 406      |\n",
      "|    ep_rew_mean     | 1.42e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 396      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 576      |\n",
      "|    total_timesteps | 98376    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -263     |\n",
      "|    critic_loss     | 4.33     |\n",
      "|    ent_coef        | 0.0542   |\n",
      "|    ent_coef_loss   | -0.761   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 98275    |\n",
      "---------------------------------\n",
      "[DORAEMON] Step 100376: Success=0.74 | Lambda=1.48 | Mean=[1.         1.0999999  0.79999995] | Std=[0.01491827 0.01491827 0.01491827]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 409      |\n",
      "|    ep_rew_mean     | 1.43e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 588      |\n",
      "|    total_timesteps | 100376   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -263     |\n",
      "|    critic_loss     | 3.88     |\n",
      "|    ent_coef        | 0.0498   |\n",
      "|    ent_coef_loss   | 1.37     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 100275   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 414      |\n",
      "|    ep_rew_mean     | 1.45e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 404      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 599      |\n",
      "|    total_timesteps | 102241   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -266     |\n",
      "|    critic_loss     | 2.79     |\n",
      "|    ent_coef        | 0.0497   |\n",
      "|    ent_coef_loss   | 0.0804   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 102140   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 411      |\n",
      "|    ep_rew_mean     | 1.44e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 408      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 608      |\n",
      "|    total_timesteps | 103850   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -259     |\n",
      "|    critic_loss     | 4.45     |\n",
      "|    ent_coef        | 0.0486   |\n",
      "|    ent_coef_loss   | 0.591    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 103749   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 408      |\n",
      "|    ep_rew_mean     | 1.43e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 412      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 616      |\n",
      "|    total_timesteps | 105237   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -262     |\n",
      "|    critic_loss     | 4.48     |\n",
      "|    ent_coef        | 0.0479   |\n",
      "|    ent_coef_loss   | -0.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 105136   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 409      |\n",
      "|    ep_rew_mean     | 1.44e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 416      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 626      |\n",
      "|    total_timesteps | 106861   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -267     |\n",
      "|    critic_loss     | 3.57     |\n",
      "|    ent_coef        | 0.0482   |\n",
      "|    ent_coef_loss   | -0.732   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 106760   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 408      |\n",
      "|    ep_rew_mean     | 1.44e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 420      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 634      |\n",
      "|    total_timesteps | 108353   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -271     |\n",
      "|    critic_loss     | 5.14     |\n",
      "|    ent_coef        | 0.0461   |\n",
      "|    ent_coef_loss   | -0.288   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 108252   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 405      |\n",
      "|    ep_rew_mean     | 1.43e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 424      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 642      |\n",
      "|    total_timesteps | 109616   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -266     |\n",
      "|    critic_loss     | 3.4      |\n",
      "|    ent_coef        | 0.0482   |\n",
      "|    ent_coef_loss   | -0.243   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 109515   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | 1.42e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 428      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 647      |\n",
      "|    total_timesteps | 110582   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -269     |\n",
      "|    critic_loss     | 2.95     |\n",
      "|    ent_coef        | 0.0455   |\n",
      "|    ent_coef_loss   | -0.0582  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 110481   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 401      |\n",
      "|    ep_rew_mean     | 1.42e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 432      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 655      |\n",
      "|    total_timesteps | 111925   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -271     |\n",
      "|    critic_loss     | 4.29     |\n",
      "|    ent_coef        | 0.0446   |\n",
      "|    ent_coef_loss   | 0.0543   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 111824   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 397      |\n",
      "|    ep_rew_mean     | 1.41e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 436      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 665      |\n",
      "|    total_timesteps | 113567   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -261     |\n",
      "|    critic_loss     | 3.59     |\n",
      "|    ent_coef        | 0.0498   |\n",
      "|    ent_coef_loss   | -0.393   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 113466   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 404      |\n",
      "|    ep_rew_mean     | 1.43e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 440      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 675      |\n",
      "|    total_timesteps | 115371   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -270     |\n",
      "|    critic_loss     | 6.19     |\n",
      "|    ent_coef        | 0.0454   |\n",
      "|    ent_coef_loss   | -0.361   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 115270   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 404      |\n",
      "|    ep_rew_mean     | 1.43e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 444      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 683      |\n",
      "|    total_timesteps | 116772   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -277     |\n",
      "|    critic_loss     | 3.46     |\n",
      "|    ent_coef        | 0.0479   |\n",
      "|    ent_coef_loss   | 0.729    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 116671   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 407      |\n",
      "|    ep_rew_mean     | 1.45e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 448      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 693      |\n",
      "|    total_timesteps | 118546   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -270     |\n",
      "|    critic_loss     | 3.15     |\n",
      "|    ent_coef        | 0.0447   |\n",
      "|    ent_coef_loss   | 0.0975   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 118445   |\n",
      "---------------------------------\n",
      "[DORAEMON] Step 119416: Success=0.56 | Lambda=1.50 | Mean=[1.05       1.1499999  0.74999994] | Std=[0.01568315 0.01568315 0.01568315]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 410      |\n",
      "|    ep_rew_mean     | 1.46e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 452      |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 704      |\n",
      "|    total_timesteps | 120232   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -269     |\n",
      "|    critic_loss     | 3.12     |\n",
      "|    ent_coef        | 0.0445   |\n",
      "|    ent_coef_loss   | -0.294   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 120131   |\n",
      "---------------------------------\n",
      "Interrupted! Saving emergency checkpoint...\n",
      "Saving checkpoint at step 120805...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type float32 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/Universita/Robot_Learning/project/project-extension-bartolini_benvenuti/modules/trainer.py:130\u001b[0m, in \u001b[0;36mtrain_agent\u001b[0;34m(config, log_dir, resume_step)\u001b[0m\n\u001b[1;32m    128\u001b[0m total_steps \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimesteps\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 130\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdoraemon_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_timesteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Final Save\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/stable_baselines3/sac/sac.py:313\u001b[0m, in \u001b[0;36mSAC.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfSAC,\n\u001b[1;32m    306\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    312\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfSAC:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:335\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 335\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rollout\u001b[38;5;241m.\u001b[39mcontinue_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:568\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:222\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_normalize.py:181\u001b[0m, in \u001b[0;36mVecNormalize.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03mApply sequence of actions to sequence of environments\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03mactions -> (observations, rewards, dones)\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03mwhere ``dones`` is a boolean vector indicating whether each element is new.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, (np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mdict\u001b[39m))  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:59\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 59\u001b[0m     obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/gymnasium/core.py:327\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/gymnasium/wrappers/common.py:125\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/gymnasium/wrappers/common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/gymnasium/core.py:327\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/gymnasium/wrappers/common.py:285\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Universita/Robot_Learning/project/project-extension-bartolini_benvenuti/env/custom_hopper.py:167\u001b[0m, in \u001b[0;36mCustomHopper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    166\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_obs()\n\u001b[0;32m--> 167\u001b[0m reward, reward_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_rew\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_velocity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m terminated \u001b[38;5;241m=\u001b[39m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_healthy) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_terminate_when_unhealthy\n",
      "File \u001b[0;32m~/Desktop/Universita/Robot_Learning/project/project-extension-bartolini_benvenuti/env/custom_hopper.py:183\u001b[0m, in \u001b[0;36mCustomHopper._get_rew\u001b[0;34m(self, x_velocity, action)\u001b[0m\n\u001b[1;32m    182\u001b[0m forward_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_reward_weight \u001b[38;5;241m*\u001b[39m x_velocity\n\u001b[0;32m--> 183\u001b[0m healthy_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhealthy_reward\u001b[49m\n\u001b[1;32m    184\u001b[0m rewards \u001b[38;5;241m=\u001b[39m forward_reward \u001b[38;5;241m+\u001b[39m healthy_reward\n",
      "File \u001b[0;32m~/Desktop/Universita/Robot_Learning/project/project-extension-bartolini_benvenuti/env/custom_hopper.py:127\u001b[0m, in \u001b[0;36mCustomHopper.healthy_reward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhealthy_reward\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_healthy\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_healthy_reward\n",
      "File \u001b[0;32m~/Desktop/Universita/Robot_Learning/project/project-extension-bartolini_benvenuti/env/custom_hopper.py:142\u001b[0m, in \u001b[0;36mCustomHopper.is_healthy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m min_angle, max_angle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_healthy_angle_range\n\u001b[0;32m--> 142\u001b[0m healthy_state \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_and\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m healthy_z \u001b[38;5;241m=\u001b[39m min_z \u001b[38;5;241m<\u001b[39m z \u001b[38;5;241m<\u001b[39m max_z\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:2510\u001b[0m, in \u001b[0;36m_all_dispatcher\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_all_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   2509\u001b[0m                     where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 2510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, where, out)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model, env, doraemon_cb \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Universita/Robot_Learning/project/project-extension-bartolini_benvenuti/modules/trainer.py:139\u001b[0m, in \u001b[0;36mtrain_agent\u001b[0;34m(config, log_dir, resume_step)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted! Saving emergency checkpoint...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m     \u001b[43mdoraemon_cb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, env, doraemon_cb\n",
      "File \u001b[0;32m~/Desktop/Universita/Robot_Learning/project/project-extension-bartolini_benvenuti/modules/callbacks.py:174\u001b[0m, in \u001b[0;36mDoraemonCallback.save_checkpoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m state \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimesteps\u001b[39m\u001b[38;5;124m\"\u001b[39m: step,\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabda),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\n\u001b[1;32m    172\u001b[0m }\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/doraemon_state_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 174\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# 3. Save SB3 Components\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/json/encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/json/encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/RL_lab04/lib/python3.9/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type float32 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model, env, doraemon_cb = train_agent(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e84385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files found: ['doraemon_state_151660.json', 'doraemon_state_156701.json', 'vecnormalize_156701.pkl', 'vecnormalize_156311.pkl', 'doraemon_state_156311.json', 'doraemon_state_158913.json', 'replay_buffer_151660.pkl', 'model_156311.zip', 'model_156701.zip', 'replay_buffer_158913.pkl', 'model_151660.zip', 'replay_buffer_156701.pkl', 'replay_buffer_156311.pkl', 'model_158913.zip', 'vecnormalize_151660.pkl', 'doraemon_state_120805.json', 'vecnormalize_158913.pkl']\n",
      "Resuming from step: 158913\n",
      "--- RESUMING TRAINING FROM STEP 158913 ---\n",
      "Loaded VecNormalize stats.\n",
      "Loaded Model and Replay Buffer.\n",
      "Restored DORAEMON: Lambda=1.52, Mean=[1.0999999046325684, 1.1999998092651367, 0.6999999284744263], Std=[0.01648724265396595, 0.01648724265396595, 0.01648724265396595]\n",
      "Logging to ./tensorboard_logs/SAC_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 420      |\n",
      "|    ep_rew_mean     | 1.53e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 544      |\n",
      "|    fps             | 151      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 159913   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -285     |\n",
      "|    critic_loss     | 2.01     |\n",
      "|    ent_coef        | 0.041    |\n",
      "|    ent_coef_loss   | -0.524   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 159810   |\n",
      "---------------------------------\n",
      "Interrupted! Saving emergency checkpoint...\n",
      "Saving checkpoint at step 160029...\n"
     ]
    }
   ],
   "source": [
    "# ONLY USE IF TRAINING WAS INTERRUPTED AND YOU HAVE CHECKPOINTS\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "# CHECKPOINT VERIFICATION\n",
    "\n",
    "checkpoint_dir = \"./logs/checkpoints\"\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"Files found:\", os.listdir(checkpoint_dir))\n",
    "else:\n",
    "    print(\"No checkpoints found! The interrupt save didn't work.\")\n",
    "\n",
    "\n",
    "# RESUME TRAINING FROM CHECKPOINT\n",
    "\n",
    "# 1. Find the latest checkpoint step\n",
    "log_dir = \"./logs/\"\n",
    "ckpt_dir = os.path.join(log_dir, \"checkpoints\")\n",
    "\n",
    "latest_step = None\n",
    "if os.path.exists(ckpt_dir):\n",
    "    # regex to find numbers in filenames\n",
    "    steps = [int(re.search(r'\\d+', f).group()) for f in os.listdir(ckpt_dir) if \"model_\" in f]\n",
    "    if steps:\n",
    "        latest_step = max(steps)\n",
    "\n",
    "print(f\"Resuming from step: {latest_step}\")\n",
    "\n",
    "# 2. Resume Training\n",
    "if latest_step is not None:\n",
    "    # Pass the step number to resume_step\n",
    "    model, env, doraemon_cb = train_agent(config, log_dir=log_dir, resume_step=latest_step)\n",
    "else:\n",
    "    print(\"Could not find a checkpoint to resume.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f1867e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doraemon_cb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# plot_learning_curve(\"./logs/\")\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plot_doraemon_dynamics(\u001b[43mdoraemon_cb\u001b[49m) \u001b[38;5;66;03m# uses the new function from utils.py\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'doraemon_cb' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot\n",
    "# plot_learning_curve(\"./logs/\")\n",
    "plot_doraemon_dynamics(doraemon_cb) # uses the new function from utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d8fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "def evaluate_sim2real(model, source_env_raw, target_env_raw, log_dir, model_name, n_eval_episodes=20):\n",
    "    \"\"\"\n",
    "    Evaluates the model on Source (Training Domain) vs Target (Shifted Domain).\n",
    "    Crucially, it applies the SAME Normalization stats used during training.\n",
    "    \"\"\"\n",
    "    # 1. Wrap raw envs into Vectorized Envs (required for SB3)\n",
    "    source_vec = DummyVecEnv([lambda: source_env_raw])\n",
    "    target_vec = DummyVecEnv([lambda: target_env_raw])\n",
    "\n",
    "    # 2. Load Normalization Statistics\n",
    "    # We must use the stats (mean/var) from the TRAINED agent, not new ones!\n",
    "    norm_path = f\"{log_dir}/{model_name}_vecnormalize.pkl\"\n",
    "    \n",
    "    try:\n",
    "        # Load the stats and apply them to the new envs\n",
    "        source_vec = VecNormalize.load(norm_path, source_vec)\n",
    "        target_vec = VecNormalize.load(norm_path, target_vec)\n",
    "        \n",
    "        # IMPORTANT: Turn off training updates and reward normalization for evaluation\n",
    "        source_vec.training = False\n",
    "        source_vec.norm_reward = False\n",
    "        target_vec.training = False\n",
    "        target_vec.norm_reward = False\n",
    "        \n",
    "        print(f\"Loaded Normalization stats from {norm_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: No normalization stats found. Evaluating with RAW observations (Expect poor performance).\")\n",
    "\n",
    "    # 3. Evaluate on Source (The \"Sim\")\n",
    "    print(\"\\n--- Evaluating on SOURCE Env (Simulation) ---\")\n",
    "    mean_reward, std_reward = evaluate_policy(model, source_vec, n_eval_episodes=n_eval_episodes, deterministic=True)\n",
    "    print(f\"Source Reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "    # 4. Evaluate on Target (The \"Real\")\n",
    "    print(\"\\n--- Evaluating on TARGET Env (Real/Shifted) ---\")\n",
    "    mean_reward_real, std_reward_real = evaluate_policy(model, target_vec, n_eval_episodes=n_eval_episodes, deterministic=True)\n",
    "    print(f\"Target Reward: {mean_reward_real:.2f} +/- {std_reward_real:.2f}\")\n",
    "    \n",
    "    return mean_reward, mean_reward_real\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# EXECUTION\n",
    "# ---------------------------------------------------------\n",
    "# Define the raw environments\n",
    "source_env = gym.make('CustomHopper-source-v0')\n",
    "target_env = gym.make('CustomHopper-target-v0')\n",
    "\n",
    "# Reconstruct the model name used in training\n",
    "model_name = f\"{config['algo']}_doraemon_{config['seed']}\"\n",
    "\n",
    "# Run evaluation\n",
    "evaluate_sim2real(model, source_env, target_env, log_dir=\"./logs/\", model_name=model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL_lab04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
